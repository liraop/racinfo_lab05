{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import nltk \n",
    "import heapq\n",
    "from nltk import RegexpTokenizer as rpt\n",
    "from nltk.corpus import stopwords as sw\n",
    "from string import punctuation \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = sw.words('portuguese')\n",
    "\n",
    "data_url=\"https://raw.githubusercontent.com/liraop/recinfo_lab2/master/data/results.csv\"\n",
    "data = pd.read_csv(data_url).replace(np.nan, '', regex=True)\n",
    "documents = data.text.count()\n",
    "\n",
    "def parse(text):\n",
    "    words = []\n",
    "    word_pattern = rpt(r'\\w+')\n",
    "    year_pattern = rpt(r'\\d{4}')\n",
    "    \n",
    "    patterns = [word_pattern, year_pattern]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        tokens = []\n",
    "        for token in pattern.tokenize(text):\n",
    "            if token not in stopwords and len(token) > 3:\n",
    "                tokens.append(token)\n",
    "        words.extend(tokens)\n",
    "    return words\n",
    "\n",
    "\n",
    "def build_index(dataset):\n",
    "    document_index = 0\n",
    "    index = {\"doc_row\": []}\n",
    "    \n",
    "    for entry in dataset.text:\n",
    "        document_index = document_index + 1\n",
    "        index[\"doc_row\"].append(document_index)\n",
    "            \n",
    "        for ngram in parse(entry):\n",
    "                if ngram in index: #is ngram already on index?\n",
    "                    if document_index in index[ngram]: # is it in the same document?\n",
    "                        index[ngram][document_index] = index[ngram][document_index] + 1\n",
    "                    else: # nope\n",
    "                        index[ngram][document_index] = 1 \n",
    "                else: # no, sir\n",
    "                    index[ngram] = {document_index: 1}\n",
    "    \n",
    "    return index\n",
    "                        \n",
    "index = build_index(data)\n",
    "\n",
    "queries = [\"juíza\",\"federal\",\"governo\",\"Brasil\",\"presidente\"]\n",
    "\n",
    "def get_inter_ab(index, word1, word2):\n",
    "    docs = 0.0\n",
    "    \n",
    "    if word1 not in index or word2 not in index:\n",
    "        return 0.0\n",
    "    \n",
    "    word1_inverted_list = index[word1].keys()\n",
    "    word2_inverted_list = index[word2].keys()\n",
    "    \n",
    "    for doc_id in word1_inverted_list:\n",
    "        if doc_id in word2_inverted_list:\n",
    "            docs += 1.0\n",
    "    \n",
    "    return docs\n",
    "\n",
    "def get_n_word(index,word):\n",
    "    if word in index:\n",
    "        inverted_list = index[word]\n",
    "        return float(len(inverted_list))\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcule as top-10 palavras mais associadas a cada uma dessas 5 palavras de acordo com as 4 métricas que vimos na aula. Você deve produzir uma tabela similar à tabela 6.3 do capítulo 6 do livro texto (pág. 204). Qual métrica você acha que obteve os melhores resultados? Por que? (20 pts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(index, word1, word2):\n",
    "    n_a = get_n_word(index,word1)\n",
    "    n_b = get_n_word(index,word2)\n",
    "    n_ab = get_inter_ab(index,word1,word2)\n",
    "    \n",
    "    dom = n_a + n_b            \n",
    "    \n",
    "    if dom == 0.0:\n",
    "        return 0\n",
    "    else:\n",
    "        return n_ab/dom\n",
    "\n",
    "def emim(index, word1, word2):\n",
    "    n_a = get_n_word(index,word1)\n",
    "    n_b = get_n_word(index,word2)\n",
    "    n_ab = get_inter_ab(index,word1,word2)\n",
    "    \n",
    "    \n",
    "    dom = n_a * n_b\n",
    "    factor = 0\n",
    "    \n",
    "    if (dom != 0):\n",
    "        factor = N * (n_ab/dom)\n",
    "        \n",
    "    if factor == 0: return 0\n",
    "       \n",
    "    return n_ab * math.log10(factor)\n",
    "\n",
    "\n",
    "def x2(index, word1, word2):\n",
    "    n_a = get_n_word(index,word1)\n",
    "    n_b = get_n_word(index,word2)\n",
    "    n_ab = get_inter_ab(index,word1,word2)\n",
    "    \n",
    "    dom = n_a * n_b\n",
    "    \n",
    "    if (dom == 0): return 0\n",
    "    \n",
    "    num = math.pow((n_ab - (1/N)*n_a*n_b),2)\n",
    "    \n",
    "    return num/dom\n",
    "    \n",
    "def mim(index, word1, word2):\n",
    "    n_a = get_n_word(index,word1)\n",
    "    n_b = get_n_word(index,word2)\n",
    "    n_ab = get_inter_ab(index,word1,word2)\n",
    "    \n",
    "    dom = n_a * n_b            \n",
    "    \n",
    "    if dom == 0.0:\n",
    "        return 0\n",
    "    else:\n",
    "        return n_ab/dom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De acordo com a métrica que deu os melhores resultados na sua opinião, execute agora cada consulta (usando a abordagem documento- ou termo-por-vez)  expandido-a com: os top-3, top-5 e top-10 documentos. O que acontece com a qualidade dos resultados em cada caso? Aumenta ou diminui? Justifique bem sua resposta. (25 pts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
