{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import nltk \n",
    "import heapq\n",
    "from nltk import RegexpTokenizer as rpt\n",
    "from nltk.corpus import stopwords as sw\n",
    "from string import punctuation \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stopwords = sw.words('portuguese')\n",
    "\n",
    "data_url=\"https://raw.githubusercontent.com/liraop/recinfo_lab2/master/data/results.csv\"\n",
    "data = pd.read_csv(data_url).replace(np.nan, '', regex=True)\n",
    "documents = data.text.count()\n",
    "\n",
    "def parse(text):\n",
    "    words = []\n",
    "    word_pattern = rpt(r'\\w+')\n",
    "    year_pattern = rpt(r'\\d{4}')\n",
    "    \n",
    "    patterns = [word_pattern, year_pattern]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        tokens = []\n",
    "        for token in pattern.tokenize(text):\n",
    "            if token not in stopwords and len(token) > 3:\n",
    "                tokens.append(token)\n",
    "        words.extend(tokens)\n",
    "    return words\n",
    "\n",
    "\n",
    "def build_index(dataset):\n",
    "    document_index = 0\n",
    "    index = {\"doc_row\": []}\n",
    "    \n",
    "    for entry in dataset.text:\n",
    "        document_index = document_index + 1\n",
    "        index[\"doc_row\"].append(document_index)\n",
    "            \n",
    "        for ngram in parse(entry):\n",
    "                if ngram in index: #is ngram already on index?\n",
    "                    if document_index in index[ngram]: # is it in the same document?\n",
    "                        index[ngram][document_index] = index[ngram][document_index] + 1\n",
    "                    else: # nope\n",
    "                        index[ngram][document_index] = 1 \n",
    "                else: # no, sir\n",
    "                    index[ngram] = {document_index: 1}\n",
    "    \n",
    "    return index\n",
    "                        \n",
    "index = build_index(data)\n",
    "\n",
    "queries = [\"juíza\",\"federal\",\"governo\",\"Brasil\",\"presidente\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcule as top-10 palavras mais associadas a cada uma dessas 5 palavras de acordo com as 4 métricas que vimos na aula. Você deve produzir uma tabela similar à tabela 6.3 do capítulo 6 do livro texto (pág. 204). Qual métrica você acha que obteve os melhores resultados? Por que? (20 pts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mim(index, word1, word2):\n",
    "    n_word1 = 0.0\n",
    "    n_word2 = 0.0\n",
    "    n_w1w2 = 0.0\n",
    "    \n",
    "    if word1 in index:\n",
    "        inverted_list = index[word1]\n",
    "        n_word1 = len(inverted_list)\n",
    "    \n",
    "    if word2 in index:\n",
    "        inverted_list = index[word1]\n",
    "        n_word2 = len(inverted_list)\n",
    "    \n",
    "    if n_word1 != 0 and n_word2 != 0:\n",
    "        word1_list = index[word1]\n",
    "        word2_list = index[word2]\n",
    "        \n",
    "        for document in word1_list.keys():\n",
    "            if document in word2_list:\n",
    "                n_w1w2 += 1\n",
    "    \n",
    "    n_w1xw2 = n_word1 * n_word2\n",
    "    return n_w1w2/n_w1xw2\n",
    "\n",
    "\n",
    "def dice(index, word1, word2):\n",
    "    n_word1 = 0.0\n",
    "    n_word2 = 0.0\n",
    "    n_w1w2 = 0.0\n",
    "        \n",
    "    if word1 in index:\n",
    "        inverted_list = index[word1]\n",
    "        n_word1 = len(inverted_list)\n",
    "    \n",
    "    if word2 in index:\n",
    "        inverted_list = index[word1]\n",
    "        n_word2 = len(inverted_list)\n",
    "    \n",
    "    if n_word1 != 0 and n_word2 != 0:\n",
    "        word1_list = index[word1]\n",
    "        word2_list = index[word2]\n",
    "        \n",
    "        for document in word1_list.keys():\n",
    "            if document in word2_list:\n",
    "                n_w1w2 += 1\n",
    "                \n",
    "    n_w1pw2 = n_word1 + n_word2\n",
    "    return n_w1w2/n_w1pw2\n",
    "\n",
    "\n",
    "\n",
    "def get_query_top10rank(index, query, metric):\n",
    "    lst=[]\n",
    "    for word in index.keys():\n",
    "        if word != 'doc_row' and word != query:\n",
    "          lst.append([word, metric(index, query, word)])\n",
    "    \n",
    "    df_tmp = pd.DataFrame(lst, columns=[\"word\", \"metric\"])\n",
    "    df_tmp['r']= df_tmp.metric.rank(ascending=False, method=\"first\")\n",
    "    df_tmp.sort_values(\"r\", inplace = True) \n",
    "    \n",
    "    y = []\n",
    "    for i in range(10):\n",
    "        y.append(df_tmp[:10].word.get(i))\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De acordo com a métrica que deu os melhores resultados na sua opinião, execute agora cada consulta (usando a abordagem documento- ou termo-por-vez)  expandido-a com: os top-3, top-5 e top-10 documentos. O que acontece com a qualidade dos resultados em cada caso? Aumenta ou diminui? Justifique bem sua resposta. (25 pts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
